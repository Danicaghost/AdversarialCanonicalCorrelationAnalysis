{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from datetime import datetime\n",
    "import os\n",
    "from os import path\n",
    "from tempfile import TemporaryFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import pycuda\n",
    "from pycuda import compiler\n",
    "import pycuda.driver as drv\n",
    "from Datasets import Noisy_MNIST_Dataset, Tangled_MNIST_Dataset\n",
    "from Plotting import plot_embeddings_single, plot_embeddings_private, display_reconstructions, save_disentangling_curves_single, save_disentangling_curves_private, grid_plot2d_single, grid_plot2d_private, plot_3d_embeddings, display_generated_images\n",
    "from Nets import ACCA_Single, ACCA_Private, VCCA_Single, VCCA_Private, Discriminator_Really_Small, beefy_decoder, encoder\n",
    "from Model_Training import train_acca_single, train_acca_private, train_vcca_single, train_vcca_private\n",
    "from sklearn.svm import LinearSVC, LinearSVR\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import multivariate_normal\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Parameters\n",
    "MNIST_type = 'MNIST' # choose from {'MNIST', 'FashionMNIST', 'KMNIST'}\n",
    "cuda = True # change to False if not using GPUs\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = Tangled_MNIST_Dataset(mnist_type=MNIST_type, train=True)\n",
    "test_dataset = Tangled_MNIST_Dataset(mnist_type=MNIST_type, train=False)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader( # not using out-of-sample validation - using training data.  This is used to evaluate information content of representation\n",
    "    train_dataset,\n",
    "    batch_size=50000, shuffle=False, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=10000, shuffle=True, **kwargs)\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: No Private Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 1.2 ACCA_Single on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 5\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    random generations \n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 1000\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 5\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "disc_multiplier = 6 # a complexity multiplier (number of neurons) for the Discriminator_Really_Small discriminator - see Nets.py\n",
    "recon_loss = 'L2'\n",
    "results_path = './results/1/2/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "acca_single5 = ACCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob)\n",
    "discriminator_z_single5 = Discriminator_Really_Small(z_dim, disc_multiplier)  #max(z_dim, 6))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    acca_single5 = nn.DataParallel(acca_single5)\n",
    "\n",
    "# Train Model - returns (best_accuracy, best_epoch, best_state_dict, results, ae.state_dict(), best_acc_state_dict, models)\n",
    "best_result, best_epoch, acca5_best_state_dict, results, last_state_dict, acca5_best_acc_state_dict, acca5_models = train_acca_single(acca_single5.to(device), z_dim, discriminator_z_single5.to(device), train_loader, validation_loader, test_loader, num_epochs, recon_loss, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. reconstructions\n",
    "    2. training curves - 3 losses, class, rota, rotb\n",
    "    3. random generations\n",
    "\"\"\"\n",
    "# Load best model\n",
    "acca_single5.load_state_dict(acca5_best_state_dict)\n",
    "acca_single5.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "# Gather embeddings and reconstructions\n",
    "z = acca_single5.module.encode(x.to(device),y.to(device))\n",
    "x_hat, y_hat = acca_single5.module.decode(z)\n",
    "z, labels, rot_x, rot_y, x_hat, y_hat = z.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. reconstructions\n",
    "display_reconstructions(x, x_hat, y, y_hat, results_path + 'acca_reconstructions.png')\n",
    "\n",
    "# 2. training curves\n",
    "save_disentangling_curves_single(results, results_path + 'acca_training_curves.png')\n",
    "\n",
    "# 3. random generations\n",
    "z_fake = torch.cuda.FloatTensor(np.random.normal(0, 1, (18, z_dim)))\n",
    "x_fake, y_fake = acca_single5.module.decode(z_fake)\n",
    "z_fake, x_fake, y_fake = z_fake.detach().cpu().numpy(), x_fake.detach().cpu().numpy(), y_fake.detach().cpu().numpy()\n",
    "display_generated_images(x_fake, y_fake, results_path + 'acca_random_generations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 1.1 VCCA_Single on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 5\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    random generations\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 1000\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 5\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "results_path = './results/1/2/vcca'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "vcca_single5 = VCCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    vcca_single5 = nn.DataParallel(vcca_single5)\n",
    "\n",
    "best_result, best_epoch, vcca5_best_state_dict, results, last_state_dict, vcca5_best_acc_state_dict, vcca5_models = train_vcca_single(vcca_single5.to(device), z_dim, train_loader, validation_loader, test_loader, num_epochs, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. reconstructions\n",
    "    2. training curves - 3 losses, class, rota, rotb\n",
    "    3. random generations\n",
    "\"\"\"\n",
    "# Load best model\n",
    "vcca_single5.load_state_dict(vcca5_best_state_dict)\n",
    "vcca_single5.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "x_hat, y_hat, z_mu, z_logvar, z = vcca_single5(x.to(device),y.to(device))\n",
    "z, labels, rot_x, rot_y, x_hat, y_hat = z.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. reconstructions\n",
    "display_reconstructions(x, x_hat, y, y_hat, results_path + 'vcca_reconstructions.png')\n",
    "\n",
    "# 2. training curves\n",
    "save_disentangling_curves_single(results, results_path + 'vcca_training_curves.png')\n",
    "\n",
    "# 3. random generations\n",
    "z_fake = torch.cuda.FloatTensor(np.random.normal(0, 1, (18, z_dim)))\n",
    "x_fake, y_fake = vcca_single5.module.decode(z_fake)\n",
    "z_fake, x_fake, y_fake = z_fake.detach().cpu().numpy(), x_fake.detach().cpu().numpy(), y_fake.detach().cpu().numpy()\n",
    "display_generated_images(x_fake, y_fake, results_path + 'vcca_random_generations.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 1.1 ACCA_Single on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 2\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    random generations over (-3,3)x(-3,3)\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 1000\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 2\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "disc_multiplier = 6 # a complexity multiplier (number of neurons) for the Discriminator_Really_Small discriminator - see Nets.py\n",
    "recon_loss = 'L2'\n",
    "results_path = './results/1/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "acca_single2 = ACCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob)\n",
    "discriminator_z_single2 = Discriminator_Really_Small(z_dim, disc_multiplier)  #max(z_dim, 6))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    acca_single2 = nn.DataParallel(acca_single2)\n",
    "\n",
    "# Train Model\n",
    "best_result, best_epoch, acca2_best_state_dict, acca2_results, acca2_last_state_dict, acca2_best_acc_state_dict, acca2_models = train_acca_single(acca_single2.to(device), z_dim, discriminator_z_single2.to(device), train_loader, validation_loader, test_loader, num_epochs, recon_loss, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "    4. random generations over (-4,4)x(-4,4)\n",
    "\"\"\"\n",
    "# Load best model\n",
    "acca_single2.load_state_dict(acca2_best_acc_state_dict)\n",
    "acca_single2.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "z = acca_single2.module.encode(x.to(device),y.to(device))\n",
    "x_hat, y_hat = acca_single2.module.decode(z)\n",
    "z_acca, labels_acca, rot_x_acca, rot_y_acca, x_hat_acca, y_hat_acca = z.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "# test\n",
    "plot_embeddings_single(z_acca,labels_acca,rot_x_acca,rot_y_acca,results_path + 'acca_embeddings.png')\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat_acca, y, y_hat_acca, results_path + 'acca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_single(acca2_results, results_path + 'acca_training_curves.png')\n",
    "\n",
    "# 4. random generations over (-2.5,2.5)x(-2.5,2.5)\n",
    "grid_plot2d_single(acca_single2, results_path + 'acca_x_generations.png', output_view_name='x')\n",
    "grid_plot2d_single(acca_single2, results_path + 'acca_y_generations.png', output_view_name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 1.1 VCCA_Single on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 2\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    random generations over (-3,3)x(-3,3)\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 1000\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 2\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "results_path = './results/1/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "vcca_single2 = VCCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    vcca_single2 = nn.DataParallel(vcca_single2)\n",
    "\n",
    "best_result, best_epoch, vcca2_best_state_dict, vcca2_results, last_state_dict, vcca2_best_acc_state_dict, vcca2_models = train_vcca_single(vcca_single2.to(device), z_dim, train_loader, validation_loader, test_loader, num_epochs, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "    4. random generations over (-3,3)x(-3,3)\n",
    "\"\"\"\n",
    "# Load best model\n",
    "vcca_single2.load_state_dict(vcca2_best_state_dict)\n",
    "vcca_single2.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "x_hat, y_hat, z_mu, z_logvar, z = vcca_single2(x.to(device),y.to(device))\n",
    "z_vcca, labels_vcca, rot_x_vcca, rot_y_vcca, x_hat_vcca, y_hat_vcca = z_mu.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "# test\n",
    "plot_embeddings_single(z_vcca,labels_vcca,rot_x_vcca,rot_y_vcca,results_path + 'vcca_embeddings.png')\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat_vcca, y, y_hat_vcca, results_path + 'vcca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_single(vcca2_results, results_path + 'vcca_training_curves.png')\n",
    "\n",
    "# 4. random generations over (-2.5,2.5)x(-2.5,2.5)\n",
    "grid_plot2d_single(vcca_single2, results_path + 'vcca_x_generations.png', output_view_name='x')\n",
    "grid_plot2d_single(vcca_single2, results_path + 'vcca_y_generations.png', output_view_name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of Fit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = np.linspace(-4, 4, 100)\n",
    "y_flat = np.linspace(-4, 4, 100)\n",
    "xi, yi = np.meshgrid(x_flat, y_flat)\n",
    "\n",
    "# Create a figure with 3 plot areas\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(21, 5))\n",
    "nbins = 100\n",
    "grid_data = np.vstack([xi.flatten(), yi.flatten()]).T\n",
    "levels = np.arange(-10,0,0.5)\n",
    "\n",
    "# Gaussian plot\n",
    "rv = multivariate_normal([0, 0], [[1, 0.], [0., 1]])\n",
    "gaussiani = rv.logpdf(grid_data)\n",
    "axes[0].set_title('N(0,I) Log Probibility Contours')\n",
    "im0 = axes[0].pcolormesh(xi, yi, gaussiani.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[0].contour(xi, yi, gaussiani.reshape(xi.shape), levels=levels)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_aspect('equal', 'box')\n",
    "axes[0].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# VCCA Plot\n",
    "kde_vcca = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(z_vcca)\n",
    "zi_vcca = kde_vcca.score_samples(grid_data)\n",
    "axes[1].set_title('VCCA Embeddings on Out of Sample Data')\n",
    "im1 = axes[1].pcolormesh(xi, yi, zi_vcca.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[1].contour(xi, yi, zi_vcca.reshape(xi.shape), levels=levels)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_aspect('equal', 'box')\n",
    "axes[1].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# ACCA Plot\n",
    "kde_acca = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(z_acca)\n",
    "zi_acca = kde_acca.score_samples(grid_data)\n",
    "axes[2].set_title('ACCA Embeddings on Out of Sample Data')\n",
    "im2 = axes[2].pcolormesh(xi, yi, zi_acca.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[2].contour(xi, yi, zi_acca.reshape(xi.shape), levels=levels)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_aspect('equal', 'box')\n",
    "axes[2].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im2, ax=axes[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beefy Decoder Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 1.1 ACCA_Single on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 2\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    random generations over (-3,3)x(-3,3)\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 400\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 2\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "disc_multiplier = 6 # a complexity multiplier (number of neurons) for the Discriminator_Really_Small discriminator - see Nets.py\n",
    "recon_loss = 'L2'\n",
    "results_path = './results/1/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "acca_single2 = ACCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob, encoder_function=encoder, decoder_function=beefy_decoder)\n",
    "discriminator_z_single2 = Discriminator_Really_Small(z_dim, disc_multiplier)  #max(z_dim, 6))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    acca_single2 = nn.DataParallel(acca_single2)\n",
    "\n",
    "# Train Model\n",
    "best_result, best_epoch, acca2_best_state_dict, acca2_results, acca2_last_state_dict, acca2_best_acc_state_dict, acca2_models = train_acca_single(acca_single2.to(device), z_dim, discriminator_z_single2.to(device), train_loader, validation_loader, test_loader, num_epochs, recon_loss, device)\n",
    "\n",
    "discriminator_z_single2.cpu()\n",
    "del discriminator_z_single2\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "    4. random generations over (-4,4)x(-4,4)\n",
    "\"\"\"\n",
    "\n",
    "# Load best model\n",
    "acca_single2.load_state_dict(acca2_best_acc_state_dict)\n",
    "acca_single2.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "# x, y, rot_x, rot_y, labels = next(iter(validation_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "z = acca_single2.module.encode(x.to(device),y.to(device))\n",
    "x_hat, y_hat = acca_single2.module.decode(z)\n",
    "z_acca, labels_acca, rot_x_acca, rot_y_acca, x_hat_acca, y_hat_acca = z.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "# test\n",
    "plot_embeddings_single(z_acca,labels_acca,rot_x_acca,rot_y_acca,results_path + 'acca_embeddings.png')\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat_acca, y, y_hat_acca, results_path + 'acca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_single(acca2_results, results_path + 'acca_training_curves.png')\n",
    "\n",
    "# 4. random generations over (-2.5,2.5)x(-2.5,2.5)\n",
    "grid_plot2d_single(acca_single2, results_path + 'acca_x_generations.png', output_view_name='x')\n",
    "grid_plot2d_single(acca_single2, results_path + 'acca_y_generations.png', output_view_name='y')\n",
    "\n",
    "del acca_single2\n",
    "x.detach().cpu()\n",
    "y.detach().cpu()\n",
    "z.detach().cpu()\n",
    "del x\n",
    "del y\n",
    "del x_hat\n",
    "del y_hat\n",
    "del z\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 1.1 VCCA_Single on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 2\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    random generations over (-3,3)x(-3,3)\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 300\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 2\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "results_path = './results/1/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "vcca_single2 = VCCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob, encoder_function=encoder, decoder_function=beefy_decoder)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    vcca_single2 = nn.DataParallel(vcca_single2)\n",
    "\n",
    "best_result, best_epoch, vcca2_best_state_dict, vcca2_results, last_state_dict, vcca2_best_acc_state_dict, vcca2_models = train_vcca_single(vcca_single2.to(device), z_dim, train_loader, validation_loader, test_loader, num_epochs, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "    4. random generations over (-3,3)x(-3,3)\n",
    "\"\"\"\n",
    "# Load best model\n",
    "vcca_single2.load_state_dict(vcca2_best_state_dict)\n",
    "vcca_single2.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "# x, y, rot_x, rot_y, labels = next(iter(validation_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "x_hat, y_hat, z_mu, z_logvar, z = vcca_single2(x.to(device),y.to(device))\n",
    "z_vcca, labels_vcca, rot_x_vcca, rot_y_vcca, x_hat_vcca, y_hat_vcca = z_mu.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "# test\n",
    "plot_embeddings_single(z_vcca,labels_vcca,rot_x_vcca,rot_y_vcca,results_path + 'vcca_embeddings.png')\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat_vcca, y, y_hat_vcca, results_path + 'vcca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_single(vcca2_results, results_path + 'vcca_training_curves.png')\n",
    "\n",
    "# 4. random generations over (-2.5,2.5)x(-2.5,2.5)\n",
    "grid_plot2d_single(vcca_single2, results_path + 'vcca_x_generations.png', output_view_name='x')\n",
    "grid_plot2d_single(vcca_single2, results_path + 'vcca_y_generations.png', output_view_name='y')\n",
    "\n",
    "del vcca_single2\n",
    "x.detach().cpu()\n",
    "y.detach().cpu()\n",
    "del x\n",
    "del y\n",
    "del x_hat\n",
    "del y_hat\n",
    "del z_mu\n",
    "del z_logvar\n",
    "del z\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beefy Goodness of Fit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = np.linspace(-4, 4, 100)\n",
    "y_flat = np.linspace(-4, 4, 100)\n",
    "xi, yi = np.meshgrid(x_flat, y_flat)\n",
    "\n",
    "# Create a figure with 3 plot areas\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(21, 5))\n",
    "nbins = 100\n",
    "grid_data = np.vstack([xi.flatten(), yi.flatten()]).T\n",
    "levels = np.arange(-10,0,0.5)\n",
    "\n",
    "# Gaussian plot\n",
    "rv = multivariate_normal([0, 0], [[1, 0.], [0., 1]])\n",
    "gaussiani = rv.logpdf(grid_data)\n",
    "axes[0].set_title('N(0,I) Log Probibility Contours')\n",
    "im0 = axes[0].pcolormesh(xi, yi, gaussiani.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[0].contour(xi, yi, gaussiani.reshape(xi.shape), levels=levels)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_aspect('equal', 'box')\n",
    "axes[0].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# VCCA Plot\n",
    "kde_vcca = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(z_vcca)\n",
    "zi_vcca = kde_vcca.score_samples(grid_data)\n",
    "axes[1].set_title('VCCA Embeddings on Out of Sample Data')\n",
    "im1 = axes[1].pcolormesh(xi, yi, zi_vcca.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[1].contour(xi, yi, zi_vcca.reshape(xi.shape), levels=levels)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_aspect('equal', 'box')\n",
    "axes[1].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# ACCA Plot\n",
    "kde_acca = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(z_acca)\n",
    "zi_acca = kde_acca.score_samples(grid_data)\n",
    "axes[2].set_title('ACCA Embeddings on Out of Sample Data')\n",
    "im2 = axes[2].pcolormesh(xi, yi, zi_acca.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[2].contour(xi, yi, zi_acca.reshape(xi.shape), levels=levels)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_aspect('equal', 'box')\n",
    "axes[2].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im2, ax=axes[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Private Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCCA_Private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 2.1 VCCA_Private on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 2\n",
    "    hx_dim = 2\n",
    "    hy_dim = 2\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 300\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 1 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 2\n",
    "hx_dim = 2\n",
    "hy_dim = 2\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "results_path = './results/2/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "vcca_private = VCCA_Private(z_dim=z_dim, num_z_inputs=num_z, hx_dim=hx_dim, hy_dim=hy_dim, dropout_prob=dropout_prob)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    vcca_private = nn.DataParallel(vcca_private)\n",
    "\n",
    "# Train Model\n",
    "best_result, best_epoch, vccap_best_state_dict, vccap_results, vccap_last_state_dict, vccap_best_acc_state_dict, vccap_state_dict_list = train_vcca_private(vcca_private.to(device), z_dim, hx_dim, hy_dim, train_loader, validation_loader, test_loader, num_epochs, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "\"\"\"\n",
    "# Load best model\n",
    "vcca_private.load_state_dict(vccap_best_state_dict)\n",
    "vcca_private.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "x_val, y_val, rot_x_val, rot_y_val, labels_val = next(iter(validation_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "x_hat, y_hat, z_mu, z_logvar, hx_mu, hx_logvar, hy_mu, hy_logvar, z, hx, hy = vcca_private(x,y)\n",
    "z, hx, hy, labels, rot_x, rot_y, x_hat, y_hat = z_mu.detach().cpu().numpy(), hx_mu.detach().cpu().numpy(), hy_mu.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "# test\n",
    "plot_embeddings_private(z, hx, hy, labels, results_path + 'vcca_embeddings.png')\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat, y, y_hat, results_path + 'vcca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_private(vccap_results, results_path + 'vcca_training_curves.png')\n",
    "\n",
    "# 4. embeddings plots comparing info content\n",
    "plot_embeddings_single(z, labels, rot_x, rot_y, results_path + 'vcca_z_embeddings.png')\n",
    "plot_embeddings_single(hx, labels, rot_x, rot_y, results_path + 'vcca_hx_embeddings.png')\n",
    "plot_embeddings_single(hy, labels, rot_x, rot_y, results_path + 'vcca_hy_embeddings.png')\n",
    "\n",
    "# 5. Goodness of Fit\n",
    "x_flat = np.linspace(-4, 4, 100)\n",
    "y_flat = np.linspace(-4, 4, 100)\n",
    "xi, yi = np.meshgrid(x_flat, y_flat)\n",
    "\n",
    "# Create a figure with 4 plot areas\n",
    "fig, axes = plt.subplots(ncols=4, nrows=1, figsize=(21, 5))\n",
    "nbins = 100\n",
    "grid_data = np.vstack([xi.flatten(), yi.flatten()]).T\n",
    "levels = np.arange(-10,0,0.5)\n",
    "\n",
    "# Gaussian plot\n",
    "rv = multivariate_normal([0, 0], [[1, 0.], [0., 1]])\n",
    "gaussiani = rv.logpdf(grid_data)\n",
    "axes[0].set_title('N(0,I) Log Probibility Contours')\n",
    "im0 = axes[0].pcolormesh(xi, yi, gaussiani.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[0].contour(xi, yi, gaussiani.reshape(xi.shape), levels=levels)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_aspect('equal', 'box')\n",
    "axes[0].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# z Plot\n",
    "kde_z = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(z)\n",
    "z_scores = kde_z.score_samples(grid_data)\n",
    "axes[1].set_title('z Embeddings on Out of Sample Data')\n",
    "im1 = axes[1].pcolormesh(xi, yi, z_scores.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[1].contour(xi, yi, z_scores.reshape(xi.shape), levels=levels)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_aspect('equal', 'box')\n",
    "axes[1].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# hx Plot\n",
    "kde_hx = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(hx)\n",
    "hx_scores = kde_hx.score_samples(grid_data)\n",
    "axes[2].set_title('hx Embeddings on Out of Sample Data')\n",
    "im2 = axes[2].pcolormesh(xi, yi, hx_scores.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[2].contour(xi, yi, hx_scores.reshape(xi.shape), levels=levels)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_aspect('equal', 'box')\n",
    "axes[2].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im2, ax=axes[2])\n",
    "\n",
    "# hy Plot\n",
    "kde_hy = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(hy)\n",
    "hy_scores = kde_hy.score_samples(grid_data)\n",
    "axes[3].set_title('hy Embeddings on Out of Sample Data')\n",
    "im3 = axes[3].pcolormesh(xi, yi, hy_scores.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[3].contour(xi, yi, hy_scores.reshape(xi.shape), levels=levels)\n",
    "axes[3].axis('equal')\n",
    "axes[3].set_aspect('equal', 'box')\n",
    "axes[3].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im3, ax=axes[3])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCA-Private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 2.1 ACCA_Private on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 2\n",
    "    hx_dim = 2\n",
    "    hy_dim = 2\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 2\n",
    "batch_size = 300\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 1 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 2\n",
    "hx_dim = 2\n",
    "hy_dim = 2\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "disc_multiplier = 6 # a complexity multiplier (number of neurons) for the Discriminator_Really_Small discriminator - see Nets.py\n",
    "recon_loss = 'L2'\n",
    "results_path = './results/2/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "acca_private = ACCA_Private(z_dim=z_dim, num_z_inputs=num_z, hx_dim=hx_dim, hy_dim=hy_dim, dropout_prob=dropout_prob)\n",
    "discriminator_z = Discriminator_Really_Small(z_dim, disc_multiplier)  #max(z_dim, 6))\n",
    "discriminator_hx = Discriminator_Really_Small(hx_dim, disc_multiplier)\n",
    "discriminator_hy = Discriminator_Really_Small(hy_dim, disc_multiplier)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    acca_private = nn.DataParallel(acca_private)\n",
    "\n",
    "# Train Model\n",
    "best_result, best_epoch, accap_best_state_dict, accap_results, accap_last_state_dict, accap_best_acc_state_dict, accap_state_dict_list = train_acca_private(acca_private.to(device), z_dim, hx_dim, hy_dim, [discriminator_z.to(device), discriminator_hx.to(device), discriminator_hy.to(device)], train_loader, validation_loader, test_loader, num_epochs, recon_loss, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "\"\"\"\n",
    "# Load best model - accap_best_state_dict, accap_last_state_dict, accap_best_acc_state_dict, accap_state_dict_list\n",
    "acca_private.load_state_dict(accap_best_acc_state_dict)\n",
    "acca_private.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "x_val, y_val, rot_x_val, rot_y_val, labels_val = next(iter(validation_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "z_ten, hx_ten, hy_ten = acca_private.module.encode(x.to(device),y.to(device))\n",
    "x_hat, y_hat = acca_private.module.decode(z_ten,hx_ten,hy_ten)\n",
    "z, hx, hy, labels, rot_x, rot_y, x_hat, y_hat = z_ten.detach().cpu().numpy(), hx_ten.detach().cpu().numpy(), hy_ten.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "# test\n",
    "plot_embeddings_private(z, hx, hy, labels, results_path + 'acca_embeddings.png')\n",
    "# plot_embeddings_experiment3b(z, hx, hy, labels, rot_x, rot_y, results_path + 'acca_embeddings.png')\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat, y, y_hat, results_path + 'acca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_private(accap_results, results_path + 'acca_training_curves.png')\n",
    "\n",
    "# 4. embeddings plots comparing info content\n",
    "plot_embeddings_single(z, labels, rot_x, rot_y, results_path + 'acca_z_embeddings.png')\n",
    "plot_embeddings_single(hx, labels, rot_x, rot_y, results_path + 'acca_hx_embeddings.png')\n",
    "plot_embeddings_single(hy, labels, rot_x, rot_y, results_path + 'acca_hy_embeddings.png')\n",
    "\n",
    "# 5. Goodness of Fit\n",
    "x_flat = np.linspace(-4, 4, 100)\n",
    "y_flat = np.linspace(-4, 4, 100)\n",
    "xi, yi = np.meshgrid(x_flat, y_flat)\n",
    "\n",
    "# Create a figure with 4 plot areas\n",
    "fig, axes = plt.subplots(ncols=4, nrows=1, figsize=(21, 5))\n",
    "nbins = 100\n",
    "grid_data = np.vstack([xi.flatten(), yi.flatten()]).T\n",
    "levels = np.arange(-10,0,0.5)\n",
    "\n",
    "# Gaussian plot\n",
    "rv = multivariate_normal([0, 0], [[1, 0.], [0., 1]])\n",
    "gaussiani = rv.logpdf(grid_data)\n",
    "axes[0].set_title('N(0,I) Log Probibility Contours')\n",
    "im0 = axes[0].pcolormesh(xi, yi, gaussiani.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[0].contour(xi, yi, gaussiani.reshape(xi.shape), levels=levels)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_aspect('equal', 'box')\n",
    "axes[0].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# z Plot\n",
    "kde_z = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(z)\n",
    "z_scores = kde_z.score_samples(grid_data)\n",
    "axes[1].set_title('z Embeddings on Out of Sample Data')\n",
    "im1 = axes[1].pcolormesh(xi, yi, z_scores.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[1].contour(xi, yi, z_scores.reshape(xi.shape), levels=levels)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_aspect('equal', 'box')\n",
    "axes[1].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# hx Plot\n",
    "kde_hx = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(hx)\n",
    "hx_scores = kde_hx.score_samples(grid_data)\n",
    "axes[2].set_title('hx Embeddings on Out of Sample Data')\n",
    "im2 = axes[2].pcolormesh(xi, yi, hx_scores.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[2].contour(xi, yi, hx_scores.reshape(xi.shape), levels=levels)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_aspect('equal', 'box')\n",
    "axes[2].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im2, ax=axes[2])\n",
    "\n",
    "# hy Plot\n",
    "kde_hy = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(hy)\n",
    "hy_scores = kde_hy.score_samples(grid_data)\n",
    "axes[3].set_title('hy Embeddings on Out of Sample Data')\n",
    "im3 = axes[3].pcolormesh(xi, yi, hy_scores.reshape(xi.shape), shading='gouraud', cmap='plasma')\n",
    "axes[3].contour(xi, yi, hy_scores.reshape(xi.shape), levels=levels)\n",
    "axes[3].axis('equal')\n",
    "axes[3].set_aspect('equal', 'box')\n",
    "axes[3].set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "fig.colorbar(im3, ax=axes[3])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCA-Private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 2.1 ACCA_Private on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 4\n",
    "    hx_dim = 4\n",
    "    hy_dim = 4\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 2\n",
    "batch_size = 300\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 1 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 4\n",
    "hx_dim = 4\n",
    "hy_dim = 4\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "disc_multiplier = 6 # a complexity multiplier (number of neurons) for the Discriminator_Really_Small discriminator - see Nets.py\n",
    "recon_loss = 'L2'\n",
    "results_path = './results/2/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "acca_private = ACCA_Private(z_dim=z_dim, num_z_inputs=num_z, hx_dim=hx_dim, hy_dim=hy_dim, dropout_prob=dropout_prob)\n",
    "discriminator_z = Discriminator_Really_Small(z_dim, disc_multiplier)  #max(z_dim, 6))\n",
    "discriminator_hx = Discriminator_Really_Small(hx_dim, disc_multiplier)\n",
    "discriminator_hy = Discriminator_Really_Small(hy_dim, disc_multiplier)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    acca_private = nn.DataParallel(acca_private)\n",
    "\n",
    "# Train Model\n",
    "best_result, best_epoch, accap_best_state_dict, accap_results, accap_last_state_dict, accap_best_acc_state_dict, accap_state_dict_list = train_acca_private(acca_private.to(device), z_dim, hx_dim, hy_dim, [discriminator_z.to(device), discriminator_hx.to(device), discriminator_hy.to(device)], train_loader, validation_loader, test_loader, num_epochs, recon_loss, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "\"\"\"\n",
    "# Load best model - accap_best_state_dict, accap_last_state_dict, accap_best_acc_state_dict, accap_state_dict_list\n",
    "acca_private.load_state_dict(accap_best_acc_state_dict)\n",
    "acca_private.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "\n",
    "# Gather reconstructions and curves\n",
    "z_ten, hx_ten, hy_ten = acca_private.module.encode(x.to(device),y.to(device))\n",
    "x_hat, y_hat = acca_private.module.decode(z_ten,hx_ten,hy_ten)\n",
    "z, hx, hy, labels, rot_x, rot_y, x_hat, y_hat = z_ten.detach().cpu().numpy(), hx_ten.detach().cpu().numpy(), hy_ten.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat, y, y_hat, results_path + 'acca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_private(accap_results, results_path + 'acca_training_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCCA-Private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 2.1 VCCA_Private on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 4\n",
    "    hx_dim = 4\n",
    "    hy_dim = 4\n",
    "    q(z|x,y) not just q(z|x)\n",
    "Plots:\n",
    "    3 embedding plots - with class, rota, and rotb coloring\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    want to demonstrate goodness of fit argument\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 300\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 1 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 4\n",
    "hx_dim = 4\n",
    "hy_dim = 4\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "results_path = './results/2/1/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "vcca_private = VCCA_Private(z_dim=z_dim, num_z_inputs=num_z, hx_dim=hx_dim, hy_dim=hy_dim, dropout_prob=dropout_prob)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    vcca_private = nn.DataParallel(vcca_private)\n",
    "\n",
    "# Train Model\n",
    "best_result, best_epoch, vccap_best_state_dict, vccap_results, vccap_last_state_dict, vccap_best_acc_state_dict, vccap_state_dict_list = train_vcca_private(vcca_private.to(device), z_dim, hx_dim, hy_dim, train_loader, validation_loader, test_loader, num_epochs, device)\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. 3 embedding plots - with class, rota, and rotb coloring\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "\"\"\"\n",
    "# Load best model\n",
    "vcca_private.load_state_dict(vccap_best_state_dict)\n",
    "vcca_private.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "x_val, y_val, rot_x_val, rot_y_val, labels_val = next(iter(validation_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "x_hat, y_hat, z_mu, z_logvar, hx_mu, hx_logvar, hy_mu, hy_logvar, z, hx, hy = vcca_private(x,y)\n",
    "z, hx, hy, labels, rot_x, rot_y, x_hat, y_hat = z_mu.detach().cpu().numpy(), hx_mu.detach().cpu().numpy(), hy_mu.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat, y, y_hat, results_path + 'vcca_reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_private(vccap_results, results_path + 'vcca_training_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: S-Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ACCA_Single on Tangled MNIST\n",
    "Model params:\n",
    "    No dropout\n",
    "    z_dim = 3\n",
    "    q(z|x,y) not just q(z|x)\n",
    "    p(z) is S-Manifold Distribution\n",
    "Plots:\n",
    "    embeddings\n",
    "    reconstructions\n",
    "    training curves - 3 losses, class, rota, rotb\n",
    "    random generations \n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Experiment Paramaters\n",
    "# num_epochs = 100\n",
    "batch_size = 1000\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "z_dim = 3\n",
    "dropout_prob = 0.0\n",
    "best_results = {}\n",
    "disc_multiplier = 6 # a complexity multiplier (number of neurons) for the Discriminator_Really_Small discriminator - see Nets.py\n",
    "recon_loss = 'L2'\n",
    "results_path = './results/1/3/'\n",
    "if not os.path.exists(results_path):  # checking on results directory\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "# Network\n",
    "acca_single_s = ACCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob)\n",
    "discriminator_z_single = Discriminator_Really_Small(z_dim, disc_multiplier)  #max(z_dim, 6))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    acca_single_s = nn.DataParallel(acca_single_s)\n",
    "\n",
    "# Train Model\n",
    "best_result, best_epoch, acca3_best_state_dict, acca3_results, acca3_last_state_dict, acca3_best_acc_state_dict, acca3_models = train_acca_single(acca_single_s.to(device), z_dim, discriminator_z_single.to(device), train_loader, validation_loader, test_loader, num_epochs, recon_loss, device, 'S_manifold')\n",
    "\n",
    "\"\"\" Generate/Save Plots\n",
    "    1. embeddings\n",
    "    2. reconstructions\n",
    "    3. training curves - 3 losses, class, rota, rotb\n",
    "    4. random generations\n",
    "\"\"\"\n",
    "# Load best model\n",
    "acca_single_s.load_state_dict(acca3_best_state_dict)\n",
    "acca_single_s.eval()\n",
    "\n",
    "# Get out-of-sample (test) data\n",
    "x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "\n",
    "# Gather embeddings and reconstructions\n",
    "z = acca_single_s.module.encode(x.to(device),y.to(device))\n",
    "x_hat, y_hat = acca_single_s.module.decode(z)\n",
    "z, labels, rot_x, rot_y, x_hat, y_hat = z.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "# 1. embeddings\n",
    "plot_3d_embeddings(z, labels, results_path + 's_prior.png', cmap_name='jet', plot_dataset=True)\n",
    "plot_3d_embeddings(z, labels, results_path + 'embedding.png', cmap_name='jet')\n",
    "plot_3d_embeddings(z, rot_x, results_path + 'embedding.png', cmap_name='jet')\n",
    "plot_3d_embeddings(z, rot_y, results_path + 'embedding.png', cmap_name='jet')\n",
    "\n",
    "# 2. reconstructions\n",
    "display_reconstructions(x, x_hat, y, y_hat, results_path + 'reconstructions.png')\n",
    "\n",
    "# 3. training curves\n",
    "save_disentangling_curves_single(acca3_results, results_path + 'training_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: Information Capacity in ACCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment4(z_dim):\n",
    "    # For reproducibility\n",
    "    torch.manual_seed(10)\n",
    "\n",
    "    # Experiment Paramaters\n",
    "    # num_epochs = 2\n",
    "    batch_size = 1000\n",
    "    train_loader = torch.utils.data.DataLoader( \n",
    "        train_dataset,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    num_z = 2 # 2 indicates encoder is q(z|x,y), 1 indicates encoder is q(z|x) - though with 1, there is no hope of view-specific info from y making it into z, only view-specific info from x\n",
    "    dropout_prob = 0.0\n",
    "    best_results = {}\n",
    "    disc_multiplier = 6 # a complexity multiplier (number of neurons) for the Discriminator_Really_Small discriminator - see Nets.py\n",
    "    recon_loss = 'L2'\n",
    "    results_path = './results/4/1/'\n",
    "    if not os.path.exists(results_path):  # checking on results directory\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    # Network\n",
    "    acca_single = ACCA_Single(z_dim=z_dim, num_z=num_z, dropout_prob=dropout_prob)\n",
    "    discriminator_z_single = Discriminator_Really_Small(z_dim, disc_multiplier)  #max(z_dim, 6))\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        acca_single = nn.DataParallel(acca_single)\n",
    "\n",
    "    # Train Model - returns (best_accuracy, best_epoch, best_state_dict, results, ae.state_dict(), best_acc_state_dict, models)\n",
    "    best_result, best_epoch, acca_best_state_dict, results, last_state_dict, acca_best_acc_state_dict, acca_models = train_acca_single(acca_single.to(device), z_dim, discriminator_z_single.to(device), train_loader, validation_loader, test_loader, num_epochs, recon_loss, device)\n",
    "\n",
    "    \"\"\" Generate/Save Plots\n",
    "        1. reconstructions\n",
    "        2. training curves - 3 losses, class, rota, rotb\n",
    "        3. random generations\n",
    "    \"\"\"\n",
    "    # Load best model\n",
    "    acca_single.load_state_dict(acca_best_state_dict)\n",
    "    acca_single.eval()\n",
    "\n",
    "    # Get out-of-sample (test) data\n",
    "    x, y, rot_x, rot_y, labels = next(iter(test_loader))\n",
    "    # Gather embeddings and reconstructions\n",
    "    z = acca_single.module.encode(x.to(device),y.to(device))\n",
    "    x_hat, y_hat = acca_single.module.decode(z)\n",
    "    z, labels, rot_x, rot_y, x_hat, y_hat = z.detach().cpu().numpy(), labels.detach().cpu().numpy(), rot_x.detach().cpu().numpy(), rot_y.detach().cpu().numpy(), x_hat.detach().cpu().numpy(), y_hat.detach().cpu().numpy()\n",
    "\n",
    "    # 1. reconstructions\n",
    "    display_reconstructions(x, x_hat, y, y_hat, results_path + 'acca_reconstructions.png')\n",
    "\n",
    "    # 2. training curves\n",
    "    save_disentangling_curves_single(results, results_path + 'acca_training_curves.png')\n",
    "\n",
    "    # 3. random generations\n",
    "    z_fake = torch.cuda.FloatTensor(np.random.normal(0, 1, (18, z_dim)))\n",
    "    x_fake, y_fake = acca_single.module.decode(z_fake)\n",
    "    z_fake, x_fake, y_fake = z_fake.detach().cpu().numpy(), x_fake.detach().cpu().numpy(), y_fake.detach().cpu().numpy()\n",
    "    display_generated_images(x_fake, y_fake, results_path + 'acca_random_generations.png')\n",
    "\n",
    "    return results, acca_best_state_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3, state_dict_3 = experiment4(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_4, state_dict_4 = experiment4(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_6, state_dict_6 = experiment4(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_8, state_dict_8 = experiment4(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10, state_dict_10 = experiment4(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_15, state_dict_15 = experiment4(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20, state_dict_20 = experiment4(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
